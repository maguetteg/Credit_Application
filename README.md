# Credit Application

In order to minimize losses and maximize profits, banks must carefully review financing requests. 
The purpose of this project is to develop a model to assist a fictional financial institution in improving its financing approval process. 
To do so, we have access to a large database containing information about loans granted to a group of individuals, as well as the profit or loss incurred on these loans two years later. 
Our goal is to maximize the bank's profits.      


To accomplish this task, several models will be considered (logistic regression, random forest, boosting techniques, bagging techniques etc.) and their performances will be compared.   



<font size="3"> To evaluate the performance of the differents models, we'll look at the following metrics. </font>  

- <font size="3"> **Accuracy** measures how often a model is correct. In our context, it measures how often safe loans are correctly classified as safe and risky loans correctly classified as risky by a model </font>     

- <font size="3"> **False positive rate** is the proportion of safe loans that were incorrectly classified as risky by a model. </font>    

- <font size="3"> **False negative rate** is the proportion of risky loans that were incorrectly classified as safe by a model. </font>   

- <font size="3"> **Precision** is the proportion of truly risky loans among all the loans that were predicted as risky </font>     

- <font size="3"> **Sensitivity** (also callded **true positive rate**) measures how good a model is at correctly identifying risky loans. It is the proportion of risky loans that were correctly classified as risky by a model.  </font>     

- <font size="3"> **Specificity** (also callded **true negative rate**) measures how good a model is at identifying safe loans. It is the proportion of safe loans that were correctly classified as safe by a model. </font>








# Dataset





